{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb08e0f2-e185-4508-921b-ccc31913966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# knn/submodules from scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Data Acquisition\n",
    "from pydataset import data\n",
    "\n",
    "import acquire_cl as acq\n",
    "import prepare_functionscl as prep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bbb34-8bce-44fd-9dc1-eba608bc0e81",
   "metadata": {},
   "source": [
    "## Acquire & Prep\n",
    "\n",
    "- Use the `titanic` dataset from pydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79254fe7-30e3-405e-8417-c2a526dfff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rose = acq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3888b02e-9a4f-483f-bb38-251e7febc711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25aa6489-cb0a-4885-87ce-6d99d372defc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  891 non-null    int64  \n",
      " 1   survived      891 non-null    int64  \n",
      " 2   pclass        891 non-null    int64  \n",
      " 3   sex           891 non-null    object \n",
      " 4   age           714 non-null    float64\n",
      " 5   sibsp         891 non-null    int64  \n",
      " 6   parch         891 non-null    int64  \n",
      " 7   fare          891 non-null    float64\n",
      " 8   embarked      889 non-null    object \n",
      " 9   class         891 non-null    object \n",
      " 10  deck          203 non-null    object \n",
      " 11  embark_town   889 non-null    object \n",
      " 12  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "rose.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a0e0a5-e153-4e46-a553-f266004aece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jack = prep.prep_titanic(rose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5861caa3-32a3-460d-82c3-90f4a1ec6f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3  22.0      1      0   7.2500      0   \n",
       "1             1         1       1  38.0      1      0  71.2833      0   \n",
       "2             2         1       3  26.0      0      0   7.9250      1   \n",
       "3             3         1       1  35.0      1      0  53.1000      0   \n",
       "4             4         0       3  35.0      0      0   8.0500      1   \n",
       "\n",
       "   sex_female  sex_male  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "0           0         1                      0                       0   \n",
       "1           1         0                      1                       0   \n",
       "2           1         0                      0                       0   \n",
       "3           1         0                      0                       0   \n",
       "4           0         1                      0                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cf08e8-5920-4895-87eb-1b5924cac8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             891 non-null    int64  \n",
      " 1   survived                 891 non-null    int64  \n",
      " 2   pclass                   891 non-null    int64  \n",
      " 3   age                      714 non-null    float64\n",
      " 4   sibsp                    891 non-null    int64  \n",
      " 5   parch                    891 non-null    int64  \n",
      " 6   fare                     891 non-null    float64\n",
      " 7   alone                    891 non-null    int64  \n",
      " 8   sex_female               891 non-null    uint8  \n",
      " 9   sex_male                 891 non-null    uint8  \n",
      " 10  embark_town_Cherbourg    891 non-null    uint8  \n",
      " 11  embark_town_Queenstown   891 non-null    uint8  \n",
      " 12  embark_town_Southampton  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(5)\n",
      "memory usage: 67.0 KB\n"
     ]
    }
   ],
   "source": [
    "jack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5086b12c-b678-4160-a76f-24215e6316d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.725028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.446751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_id    survived      pclass         age       sibsp  \\\n",
       "count    891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean     445.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std      257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min        0.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%      222.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%      445.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%      667.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max      890.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            parch        fare       alone  sex_female    sex_male  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.381594   32.204208    0.602694    0.352413    0.647587   \n",
       "std      0.806057   49.693429    0.489615    0.477990    0.477990   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    7.910400    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   14.454200    1.000000    0.000000    1.000000   \n",
       "75%      0.000000   31.000000    1.000000    1.000000    1.000000   \n",
       "max      6.000000  512.329200    1.000000    1.000000    1.000000   \n",
       "\n",
       "       embark_town_Cherbourg  embark_town_Queenstown  embark_town_Southampton  \n",
       "count             891.000000              891.000000               891.000000  \n",
       "mean                0.188552                0.086420                 0.725028  \n",
       "std                 0.391372                0.281141                 0.446751  \n",
       "min                 0.000000                0.000000                 0.000000  \n",
       "25%                 0.000000                0.000000                 0.000000  \n",
       "50%                 0.000000                0.000000                 1.000000  \n",
       "75%                 0.000000                0.000000                 1.000000  \n",
       "max                 1.000000                1.000000                 1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jack.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47f2f2-0805-47e5-b908-6428828d78f0",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be28d40a-1727-4829-8455-7490bb08a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_functionscl as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e8bfeb-63fe-401d-bb4e-109993d2260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep.split_titanic(jack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "034141e0-b370-429e-9579-e98c234bb93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 13), (214, 13), (179, 13))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e6dd5b-f1a0-4212-a131-0195f172fecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'survived', 'pclass', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'alone', 'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
       "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b483e188-d282-4498-8629-46c376142862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train['survived']\n",
    "\n",
    "X_val = val.drop(columns=['survived'])\n",
    "y_val = val['survived']\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test['survived']\n",
    "\n",
    "print(X_train.columns)\n",
    "print(X_val.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "673abfd9-fa10-40a1-b0c0-e8f00dbbfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep.titanic_age_imputer(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b519eb4d-ea53-454c-bfc6-8bc733c6ec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_val.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eda40b1-7878-4cb7-8e30-cd90debda897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    307\n",
      "1    191\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find mode of target to establish baseline\n",
    "\n",
    "print(train['survived'].value_counts())\n",
    "\n",
    "# or\n",
    "# print(y_train.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d3f5150-91b6-4efd-8896-9db4d1d058bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy:61.65%\n"
     ]
    }
   ],
   "source": [
    "base_pred = (train.survived == 0)\n",
    "base_acc = base_pred.mean()\n",
    "print(f'Baseline Accuracy:{base_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8d007-1cda-4ae7-8875-64a274dd2eb9",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4547b5a1-2bbb-4604-86a8-42580991168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3db528ff-3968-4ccd-aeee-2eac289f2ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5768edf7-26bc-498e-a38e-c4a5366152a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3f/gcykrn_x5kj_vxldk0lkx7p00000gn/T/ipykernel_69251/3258659264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_pred= knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5f451-5325-45fb-b008-265f996f940e",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "This keeps happening anytime I include 'age' as a part of my df. I've tried several times to fix it to no avail, so I'm dropping the column from my df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd5a0616-9bcb-4a7d-a6b9-fc51e945d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jack.drop(columns='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "163b9c72-7678-45c4-9cfb-ba6676f11656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep.split_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a7332be-1549-4e4d-96e2-79f5ad4ab379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "802fe02f-637b-4877-971d-66d0718f118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['passenger_id', 'pclass', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n",
      "Index(['passenger_id', 'pclass', 'sibsp', 'parch', 'fare', 'alone',\n",
      "       'sex_female', 'sex_male', 'embark_town_Cherbourg',\n",
      "       'embark_town_Queenstown', 'embark_town_Southampton'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train['survived']\n",
    "\n",
    "X_val = val.drop(columns=['survived'])\n",
    "y_val = val['survived']\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test['survived']\n",
    "\n",
    "print(X_train.columns)\n",
    "print(X_val.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef9ba03e-8844-45c3-bbad-36e3b358cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn.fit(X_train, y_train)\n",
    "y_pred= knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0548819e-d35b-4274-946e-cda29519d5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffad75-20f3-40ee-81cc-f7634fa5a3cc",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a221a74d-08c5-420f-92c7-40fdb7cd3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy for train dataset\n",
    "train_acc= knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "242fb9f7-52ce-4766-860c-9d46752101d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 74.10%\n"
     ]
    }
   ],
   "source": [
    "print(f'''Train Accuracy Score: {knn.score(X_train, y_train):.2%}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98c55399-35d3-48a2-902c-5868a3a9e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.736899</td>\n",
       "      <td>0.738985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.518325</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.698902</td>\n",
       "      <td>0.740964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.706340</td>\n",
       "      <td>0.729827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.745856    0.727941  0.740964    0.736899      0.738985\n",
       "recall       0.879479    0.518325  0.740964    0.698902      0.740964\n",
       "f1-score     0.807175    0.605505  0.740964    0.706340      0.729827\n",
       "support    307.000000  191.000000  0.740964  498.000000    498.000000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d99d2496-2243-463c-82be-42e175ff4303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270,  37],\n",
       "       [ 92,  99]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_anderson = confusion_matrix(y_train, y_pred)\n",
    "mr_anderson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac4e6f-0bba-4ad5-8cb2-3c986e5ac979",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1664a35d-a8c9-4544-8295-b6a888ebb1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 74.10%,\n",
      "          Recall: 74.59%,\n",
      "          Precision: 87.95%,\n",
      "          Support Positive: 362,\n",
      "          Support Negative: 136\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.745856    0.727941  0.740964    0.736899      0.738985\n",
      "recall       0.879479    0.518325  0.740964    0.698902      0.740964\n",
      "f1-score     0.807175    0.605505  0.740964    0.706340      0.729827\n",
      "support    307.000000  191.000000  0.740964  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = mr_anderson[1,1], mr_anderson[0,1], mr_anderson[1,0], mr_anderson[0,0]\n",
    "\n",
    "All = TN + FP+ FN+ TP\n",
    "\n",
    "accuracy= (TP + TN) / All\n",
    "True_pos_rate = recall= TP/ (TP + FN)\n",
    "precision = TP/ (TP + FP)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP +TN\n",
    "classrep_knn1= pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(f'''Accuracy score: {accuracy:.2%},\n",
    "          Recall: {recall:.2%},\n",
    "          Precision: {precision:.2%},\n",
    "          Support Positive: {support_pos},\n",
    "          Support Negative: {support_neg}''')\n",
    "print(classrep_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e6049-0b30-487d-a93d-700e6217e5c6",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "\n",
    "\n",
    "Run through steps 1-3 setting k to 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4bac23f9-34d8-4cab-8900-f3e20af21ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=10) \n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred2= knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a0e8e35a-6dcb-4871-a8fb-2d3e39b1b4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1363110e-3aac-4531-88c7-68b61b4e6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 70.68%\n"
     ]
    }
   ],
   "source": [
    "print(f'''Train Accuracy Score: {knn2.score(X_train, y_train):.2%}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b5d9899-3912-44ae-b7f7-4b1b1c91261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zion = confusion_matrix(y_train, y_pred)\n",
    "classrep_knn2= pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce307d94-1f14-471e-8bfd-29b5b6642688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 74.10%,\n",
      "          Recall: 74.59%,\n",
      "          Precision: 87.95%,\n",
      "          Support Positive: 362,\n",
      "          Support Negative: 136\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.745856    0.727941  0.740964    0.736899      0.738985\n",
      "recall       0.879479    0.518325  0.740964    0.698902      0.740964\n",
      "f1-score     0.807175    0.605505  0.740964    0.706340      0.729827\n",
      "support    307.000000  191.000000  0.740964  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = zion[1,1], zion[0,1], zion[1,0], zion[0,0]\n",
    "All = TN + FP+ FN+ TP\n",
    "accuracy= (TP + TN) / All\n",
    "True_pos_rate = recall= TP/ (TP + FN)\n",
    "precision = TP/ (TP + FP)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP +TN\n",
    "classrep_knn2= pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(f'''Accuracy score: {accuracy:.2%},\n",
    "          Recall: {recall:.2%},\n",
    "          Precision: {precision:.2%},\n",
    "          Support Positive: {support_pos},\n",
    "          Support Negative: {support_neg}''')\n",
    "print(classrep_knn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3d6f0-537f-4104-9780-9f3ec458f3e9",
   "metadata": {},
   "source": [
    "**Exercise 5**\n",
    "\n",
    "\n",
    "Run through steps 1-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "afdbf502-7691-4951-96b6-c84b03d45abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=20) \n",
    "knn3.fit(X_train, y_train)\n",
    "y_pred3= knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fae04992-caed-4d88-961c-ea8a91e0aa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6a129eb6-5892-4007-a52a-b0d542b987a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 67.67%\n"
     ]
    }
   ],
   "source": [
    "print(f'''Train Accuracy Score: {knn3.score(X_train, y_train):.2%}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1095086d-14aa-430d-a631-73fd6484f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "deja_vu = confusion_matrix(y_train, y_pred)\n",
    "classrep_knn3= pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "642bf3ba-2b2f-42e5-b08c-8c81171cd480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 74.10%,\n",
      "          Recall: 74.59%,\n",
      "          Precision: 87.95%,\n",
      "          Support Positive: 362,\n",
      "          Support Negative: 136\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.745856    0.727941  0.740964    0.736899      0.738985\n",
      "recall       0.879479    0.518325  0.740964    0.698902      0.740964\n",
      "f1-score     0.807175    0.605505  0.740964    0.706340      0.729827\n",
      "support    307.000000  191.000000  0.740964  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = deja_vu[1,1], deja_vu[0,1], deja_vu[1,0], deja_vu[0,0]\n",
    "All = TN + FP+ FN+ TP\n",
    "accuracy= (TP + TN) / All\n",
    "True_pos_rate = recall= TP/ (TP + FN)\n",
    "precision = TP/ (TP + FP)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP +TN\n",
    "classrep_knn3= pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(f'''Accuracy score: {accuracy:.2%},\n",
    "          Recall: {recall:.2%},\n",
    "          Precision: {precision:.2%},\n",
    "          Support Positive: {support_pos},\n",
    "          Support Negative: {support_neg}''')\n",
    "print(classrep_knn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e32289-3176-4af5-84c8-57d7d3fb2474",
   "metadata": {},
   "source": [
    "**Exercise 6**\n",
    "\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5d090-9cf7-4c94-9732-7f398618642b",
   "metadata": {},
   "source": [
    "- The first model with 5 neighbors has a better score than the models with 10 or 20 neighbors. \n",
    "\n",
    "Scores according to neighbors:\n",
    "    \n",
    "    \n",
    "    5 neighbors:  74.1%\n",
    "    10 neighbors: 70.68%\n",
    "    20 neighbors: 67.67%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb951b4-a4a4-46ab-9aa6-ea47f95d34ce",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "\n",
    "Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d49719ea-9251-42ca-8500-78889d21c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score KNN on validate data with 5 neighbors: 57.01%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       132\n",
      "           1       0.43      0.38      0.40        82\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.54      0.53      0.53       214\n",
      "weighted avg       0.56      0.57      0.56       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[91 41]\n",
      " [51 31]]\n",
      "Accuracy score KNN on validate data with 6 neighbors: 59.35%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71       132\n",
      "           1       0.45      0.28      0.35        82\n",
      "\n",
      "    accuracy                           0.59       214\n",
      "   macro avg       0.54      0.53      0.53       214\n",
      "weighted avg       0.57      0.59      0.57       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[104  28]\n",
      " [ 59  23]]\n",
      "Accuracy score KNN on validate data with 7 neighbors: 59.35%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69       132\n",
      "           1       0.46      0.38      0.42        82\n",
      "\n",
      "    accuracy                           0.59       214\n",
      "   macro avg       0.56      0.55      0.55       214\n",
      "weighted avg       0.58      0.59      0.58       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[96 36]\n",
      " [51 31]]\n",
      "Accuracy score KNN on validate data with 8 neighbors: 62.62%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       132\n",
      "           1       0.53      0.26      0.34        82\n",
      "\n",
      "    accuracy                           0.63       214\n",
      "   macro avg       0.59      0.56      0.54       214\n",
      "weighted avg       0.60      0.63      0.59       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[113  19]\n",
      " [ 61  21]]\n",
      "Accuracy score KNN on validate data with 9 neighbors: 60.28%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71       132\n",
      "           1       0.47      0.32      0.38        82\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.56      0.55      0.54       214\n",
      "weighted avg       0.58      0.60      0.58       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[103  29]\n",
      " [ 56  26]]\n",
      "Accuracy score KNN on validate data with 10 neighbors: 59.81%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       132\n",
      "           1       0.45      0.21      0.28        82\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.54      0.52      0.50       214\n",
      "weighted avg       0.56      0.60      0.55       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[111  21]\n",
      " [ 65  17]]\n",
      "Accuracy score KNN on validate data with 11 neighbors: 63.08%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.73       132\n",
      "           1       0.53      0.32      0.40        82\n",
      "\n",
      "    accuracy                           0.63       214\n",
      "   macro avg       0.60      0.57      0.57       214\n",
      "weighted avg       0.61      0.63      0.60       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[109  23]\n",
      " [ 56  26]]\n",
      "Accuracy score KNN on validate data with 12 neighbors: 62.62%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       132\n",
      "           1       0.53      0.26      0.34        82\n",
      "\n",
      "    accuracy                           0.63       214\n",
      "   macro avg       0.59      0.56      0.54       214\n",
      "weighted avg       0.60      0.63      0.59       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[113  19]\n",
      " [ 61  21]]\n",
      "Accuracy score KNN on validate data with 13 neighbors: 62.15%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.73       132\n",
      "           1       0.51      0.30      0.38        82\n",
      "\n",
      "    accuracy                           0.62       214\n",
      "   macro avg       0.58      0.56      0.55       214\n",
      "weighted avg       0.60      0.62      0.59       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[108  24]\n",
      " [ 57  25]]\n",
      "Accuracy score KNN on validate data with 14 neighbors: 61.21%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.73       132\n",
      "           1       0.49      0.22      0.30        82\n",
      "\n",
      "    accuracy                           0.61       214\n",
      "   macro avg       0.56      0.54      0.52       214\n",
      "weighted avg       0.58      0.61      0.57       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[113  19]\n",
      " [ 64  18]]\n",
      "Accuracy score KNN on validate data with 15 neighbors: 60.75%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72       132\n",
      "           1       0.48      0.27      0.34        82\n",
      "\n",
      "    accuracy                           0.61       214\n",
      "   macro avg       0.56      0.54      0.53       214\n",
      "weighted avg       0.58      0.61      0.58       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[108  24]\n",
      " [ 60  22]]\n",
      "Accuracy score KNN on validate data with 16 neighbors: 63.08%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75       132\n",
      "           1       0.54      0.23      0.32        82\n",
      "\n",
      "    accuracy                           0.63       214\n",
      "   macro avg       0.60      0.56      0.54       214\n",
      "weighted avg       0.61      0.63      0.58       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[116  16]\n",
      " [ 63  19]]\n",
      "Accuracy score KNN on validate data with 17 neighbors: 64.49%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75       132\n",
      "           1       0.57      0.28      0.38        82\n",
      "\n",
      "    accuracy                           0.64       214\n",
      "   macro avg       0.62      0.58      0.56       214\n",
      "weighted avg       0.63      0.64      0.61       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[115  17]\n",
      " [ 59  23]]\n",
      "Accuracy score KNN on validate data with 18 neighbors: 64.95%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76       132\n",
      "           1       0.61      0.24      0.35        82\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.63      0.57      0.55       214\n",
      "weighted avg       0.64      0.65      0.60       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[119  13]\n",
      " [ 62  20]]\n",
      "Accuracy score KNN on validate data with 19 neighbors: 64.02%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75       132\n",
      "           1       0.56      0.27      0.36        82\n",
      "\n",
      "    accuracy                           0.64       214\n",
      "   macro avg       0.61      0.57      0.56       214\n",
      "weighted avg       0.62      0.64      0.60       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[115  17]\n",
      " [ 60  22]]\n",
      "Accuracy score KNN on validate data with 20 neighbors: 65.42%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.76       132\n",
      "           1       0.62      0.24      0.35        82\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.64      0.58      0.56       214\n",
      "weighted avg       0.65      0.65      0.61       214\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120  12]\n",
      " [ 62  20]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,21):\n",
    "# creating KNN classifier with number of neighbors=i\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = i)\n",
    "\n",
    "# fitting the KNN classifier with training data\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predicting churn outcome for test data\n",
    "    y_pred = knn_classifier.predict(X_val)\n",
    "\n",
    "# model score/Val accuracy\n",
    "    model_score = knn_classifier.score(X_val, y_val)\n",
    "\n",
    "# confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# getting the classification report\n",
    "    classification_rep = classification_report(y_val, y_pred)\n",
    "    \n",
    "    print(f'Accuracy score KNN on validate data with {i} neighbors: {model_score:.2%}')\n",
    "    print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb9f73-4b30-49dc-8881-c663f69af21a",
   "metadata": {},
   "source": [
    "- 5 neighbors: 57.01%\n",
    "- 10 neighbors: 59.81%\n",
    "- 20 neighbors: 65.42%\n",
    "\n",
    "Best model is 20 neighbors, but all scores are below my baseline accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
